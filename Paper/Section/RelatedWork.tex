\section{Verwandte Arbeit}
Bevor auf TensorFlow genauer eingegangen wird, gibt dieses Kapitel eine Übersicht über folgende Deep Learning Frameworks:
\begin{multicols}{2}
	\begin{itemize}
		\item Torch
		\item Caffe
		\item Caffe2
		\item Keras
		\item Chainer
		\item \acs{cntk}
		\item Apache MXNet
		\item Amazon \acs{dsstne}
		\item Eclipse \acl{dl4j}
	\end{itemize}
\end{multicols}
	
\subsection{Torch}
Torch wurde ursprünglich von Facebook entwickelt und 2017 als Open-Source Projekt veröffentlicht. Das Framework bietet zwei Hauptfunktionen: Erstens, mathematische Berechnung mit starker Unterstützung der \ac{gpu}. Dabei wird es oft als Ersatz für das bekannte Python Framework Numpy eingesetzt, da es durch die \ac{gpu}-Unterstützung eine wesentlich bessere Performance bietet. Zweitens, zur Bildung von neuronalen Netzen für Deep Learning mit maximaler Flexibilität und Geschwindigkeit \cite{Torch}. Laut DL4J zeichnet sich das Framework durch viele Modulare Funktionen aus, die sich einfach kombinieren lassen. Des Weiteren lassen sich neue Layer einfach definieren und auf der \ac{gpu} ausführen. Nachteilig ist, dass Torch keinen kommerziellen Einsatz bietet und die Dokumentation nicht vollständig sein soll \cite{DeepLearningFrameworks}. 

\subsection{Caffe}
Caffe ist ein Open-Source Projekt, das von Yangqing Jia im Rahmen seiner Doktorarbeit beim \ac{bair} initiiert wurde. Aktuell wird es vom \ac{bair} und Community Entwicklern weiterentwickelt. Mit nur wenigen Codezeilen lassen sich Modelle erstellen. Dabei lässt sich konfigurieren, ob die Berechnungen auf der \acs{cpu} oder \ac{gpu} durchgeführt werden. Caffe wird hauptsächlich zur Verarbeitung von Bildern eingesetzt und kann mit nur einer \ac{gpu} über 60 Millionen Bilder pro Tag verarbeiten \cite{Caffe}. Aktuell bietet Caffe noch keine Möglichkeit, die Berechnung verteilt auf mehreren Instanzen durchzuführen \cite{DeepLearningFrameworks}.

\subsection{Caffe2}
Der Erfinder von Caffe Yangqing Jia ist jetzt bei Facebook und arbeitet an einer Erweiterung von Caffe. Diese wurde unter dem Name Caffe2 veröffentlicht und bietet mehr Skalierbarkeit und Leichtgewichtigkeit gegenüber Caffe. Zudem erlaubt Caffe2 das Verteilen von Aufgaben bzw. Berechnung auf mehrere Instanzen \cite{Caffe2}.

\subsection{Keras}
Keras ist ein High-Level \ac{api} für neuronale Netze und basiert auf TensorFlow, welches in Kapitel \ref{sec:tensorflow} genauer erläutert wird. Die Entwicklung von Keras folgte dem Motto: "Die Fähigkeit, mit möglichst wenig Verzögerung von der Idee zum Ergebnis zu kommen, ist der Schlüssel für eine gute Forschung" \cite{Keras}. Somit ermöglicht Keras das schnelle aufsetzen und testen von neuronalen Netzen. Elephans ist eine Erweiterung für Keras und erlaubt das Verteilen einer Anwendung über mehrere Instanzen \cite{Elephas}.

\subsection{Chainer}
Chainer ist auch ein Open-Source Deep Learning Framework und bietet ein flexibles, intuitives und leistungsstarkes Mittel zur Implementierung einer ganzen Reihe von Deep-Learning-Modellen, einschließlich State-of-the-Art-Modellen wie z. B. rekurrenten neuronalen Netzen und variationalen Autoencodern. Mit Chainer können Anwendungen auf mehrere Instanzen verteilt werden und dadurch wie in Abbildung \ref{fig:chainercomparisson} zu sehen ist die Performance anderen Frameworks klar überlegen. Die optimale Performance wurde beim Verteilen einer Anwendung auf 128 \ac{gpu}s erreicht \cite{Chainer}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{Pictures/Chainer_Comparisson}
	\caption[Deep Learning Framework Vergleich]{Deep Learning Framework Vergleich \cite{Chainer}}
	\label{fig:chainercomparisson}
\end{figure}

\subsection{\acf{cntk}}
\ac{cntk} ist ein Open-Source Framework für das verteilen einer Deep-Learning Anwendung im kommerziellen Bereich. Es beschreibt neuronale Netze als eine Reihe von Rechenschritten über einen gerichteten Graphen. \ac{cntk} erlaubt dem Benutzer, populäre Modelltypen wie feed-forward DNNs, konvolutionelle neurale Netze (CNNs) und wiederkehrende neurale Netze (RNNs / LSTMs) leicht zu verwirklichen und zu kombinieren. \ac{cntk} implementiert stochastisches Gradientenabstiegsverfahren (SGD, Error Backpropagation) mit automatischer Differenzierung und Parallelisierung über mehrere \ac{gpu}s und Server hinweg \cite{CNTK}.

\subsection{Apache MXNet}
Apache MXNet ist ein modernes Open-Source Deep Learning Framework, mit dem neuronale Netze trainiert werden können. Es ist skalierbar, ermöglicht schnelles Modelltraining und unterstützt ein flexibles Programmiermodell und mehrere Programmiersprachen. Die MXNet-Bibliothek ist portabel und kann auf mehreren \ac{gpu}s und mehreren Instanzen skaliert werden. MXNet wird von den wichtigsten Public Cloud-Anbietern wie \ac{aws} und Azure unterstützt \cite{WikipediaApacheMXNet}. Amazon und Microsoft arbeiteten zusammen an einer \ac{api} für Apache MXNet und veröffentlichten im Oktober 2017 Gluon, eine neue Open-Source Deep-Learning Schnittstelle, die es Entwicklern ermöglicht, einfach und schnell Machine-Learning-Modelle zu erstellen, ohne dabei die Performance zu beeinträchtigen \cite{AWSintroducingGluon}.

\subsection{Amazon \acs{dsstne}}
Amazon \ac{dsstne} ist eine Open-Source Deep Learning Framework zum entwickeln von Empfehlungsmodellen. \ac{dsstne} wurde bei Amazon eingesetzt, um personalisierte Produktempfehlungen für ihre Kunden zu erstellen. Es ist für den produktiven Einsatz von realen Anwendungen ausgelegt, bei denen Geschwindigkeit und Skalierbarkeit gegenüber experimenteller Flexibilität im Vordergrund stehen. Training und Vorhersagen werden skaliert, wobei Berechnung und Speicherung für jede Arbeitsschicht modellparallel verteilt werden \cite{Amazon DSSTNE}.

\subsection{Eclipse \acl{dl4j}}
Eclipse \ac{dl4j} ist die erste kommerzielle, Open-Source, Deep-Learning-Bibliothek für Java und Scala. Durch die Integration mit Hadoop und Apache Spark bringt \ac{dl4j} \ac{ki} vor allem zu Geschäftsumgebungen, bei der Hadoop bereits im Einsatz ist. \ac{dl4j} zielt darauf ab, Plug-and-Play auf dem neuesten Stand der Technik zu sein, mehr Konvention als Konfiguration. Dies ermöglicht ein schnelles Prototyping für Data Scientists, Machine-Learning-Praktiker und Softwareentwickler. \ac{dl4j} ist im Maßstab anpassbar. Unter der Apache 2.0-Lizenz veröffentlicht, gehören alle Derivate von \ac{dl4j} ihren Autoren. \ac{dl4j} kann Modelle aus Frameworks wie TensorFlow, Caffe und Theano importieren \cite{dl4j}. \newline

Wie zu sehen, gibt es aktuell viele Deep Learning Frameworks. Die meisten dieser Framework sind Open-Source Projekte und auf GitHub veröffentlicht. Heutzutage ist es wichtig, dass sich diese Technologie schnell weiterentwickelt. Dies erfordert eine große Gemeinschaft an Entwicklern. Abbildung \ref{fig:githubinterestdeeplearning} zeigt das Interesse dieser Gemeinschaft an den verschiedenen Deep Learning Frameworks vom 1. Juli 2018. Das Framework TensorFlow besitzt besonders viel Interesse, deshalb wird dieses Framework im nächsten Kapitel genauer untersucht.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{Pictures/GitHubFrameworkVergleich}
	\caption[GitHub: Vergleich des Interesses in verschiedene Deep Learning Frameworks]{GitHub: Vergleich des Interesses an o.g. Deep Learning Frameworks}
	\label{fig:githubinterestdeeplearning}
\end{figure}
