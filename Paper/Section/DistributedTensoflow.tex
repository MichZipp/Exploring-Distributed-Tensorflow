\section{Verteiltes TensorFlow}
Nachdem im vorherigen Kapitel ein kurzer Überblick über TensorFlow gegeben wurde, soll jetzt die Verteilung einer TensorFlow Umgebung auf mehrere Instanzen näher betrachtet werden. Dieses Kapitel stellt nötiges Wissen bereit, das im nächsten Kapitel im Rahmen eines Tutorials zur Einrichtung einer verteilten TensorFlow Umgebung eingesetzt wird. 

\subsection{Architektur}
Im folgenden wird die Architektur einer verteilten TensorFlow Umgebung genauer beschrieben. Dabei wird zwischen dem Parameterserver und Arbeiter unterschieden.

\subsubsection{Parameterserver}
Der Parameterserver verwaltet das aktuelle Modell mit seinen Gewichtungen und Variablen und verteilt es an die Arbeiter. Falls durch mehrere Arbeiter zu viele Ein-/Ausgabe Anfragen an den Parameterserver erzeugt werden, lässt sich durch mehrere Parameterserver die Last verteilen. Mehreren Parameterserver synchronisieren das Modell untereinander. Abbildung \ref{fig:architektur-servemodel} zeigt, wie das Verteilen des Modells an die Arbeiter aussehen kann. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{Pictures/Architektur-ServeModel}
	\caption[Verteilen des Modells auf die Arbeiter]{Verteilen des Modells auf die Arbeiter}
	\label{fig:architektur-servemodel}
\end{figure}

\subsubsection{Arbeiter}
Arbeiter führen ressourcenintensive Berechnungen zur Optimierung des vom Parameterserver bereitgestellten Modells durch. Nach der Optimierung sendet der Arbeiter das neue Modell mit seinen Gewichtungen und Variablen zum Parameterserver. Je mehr Arbeiter eingesetzt werden, desto schneller und effizienter kann ein Modell trainiert werden. Abbildung \ref{fig:architektur-updatemodel} zeigt, wie die Berechnung des Modells und die Aktualisierung des Modells auf dem Parameterserver aussehen kann. Der Master Arbeiter koordiniert die Trainingsvorgänge und kümmert sich um die Initialisierung des Modells, Zählen der Anzahl der ausgeführten Trainingsschritte, Speichern und Wiederherstellen von Modellkontrollpunkten.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{Pictures/Architektur-UpdateModel}
	\caption[Berechnung des Modells auf Arbeiter + Updaten der Variablen auf dem Parameterserver]{Berechnung des Modells auf Arbeiter + Updaten der Variablen auf dem Parameterserver}
	\label{fig:architektur-updatemodel}
\end{figure}

\subsection{Datenparallelität}
Es gibt zwei verschiedene Möglichkeiten für Datenparallelität:
\subsubsection{Synchron}
Die Arbeiter lesen gleichzeitig das Modell vom Parameterserver und berechnen mit diesem ihre Trainingsoperationen und warten, bis die anderen Arbeiter fertig sind. Dann werden die Ergebnisse gemittelt und eine Aktualisierung des Modells wird an den Parameterserver gesendet. Somit hat zu jedem Zeitpunkt jeder Arbeiter das gleiche Modell.

\subsubsection{Asynchron}
Die Arbeiter lesen asynchron von den Parameterserver, berechnen ihre Trainingsoperation und senden asynchrone Aktualisierungen an den Parameterserver. Zu jedem Zeitpunkt können zwei verschiedene Arbeiter unterschiedliche Modelle besitzen.

\subsection{Weitere Möglichkeiten}
Bisher wurde die einfachste Methode beschrieben, wie ein verteilte TensorFlow Umgebung eingerichtet werden kann. Es gibt auch die Möglichkeit eine verteilte TensorFlow Umgebung auf Basis von Hadoop \cite{tensorflowhadoop}, Kubernetes \cite{tensorflowkubernetes}, Docker \cite{tensorflowdocker} und Apache Spark \cite{tensorflowspark} zu erstellen.




